{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "M-qQL1MWzlpa",
        "eOTXAQWqxWRd",
        "Wzw5lnXmzxrD"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eduardofae/RL/blob/main/AT-06/06%20-%20Eligibility%20traces.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bb481c45"
      },
      "source": [
        "## Tarefa: Implementação e Comparação de Agentes SARSA\n",
        "\n",
        "Nesta tarefa, você irá implementar o algoritmo SARSA com traços de elegibilidade (SARSA(lambda)) e compará-lo com o SARSA comum em um cenário específico. Em seguida, você treinará o agente SARSA(lambda) no grid para observar seu desempenho.\n",
        "\n",
        "**Passos:**\n",
        "\n",
        "1.  **Implementar o SARSA(lambda):** Complete a classe `SarsaLambdaAgent` para incluir a funcionalidade de traços de elegibilidade na função `updateQ`.\n",
        "2.  **Comparação em um Episódio:** Execute o código fornecido que compara o SARSA comum e o SARSA(lambda) em um único episódio com uma sequência de ações pré-definida (`simple_episode_win` e `simple_episode_loss`). Observe como os valores Q aprendidos por cada agente se diferem após este episódio.\n",
        "3.  **Treinamento do SARSA(lambda):** Treine o agente SARSA(lambda) com diferentes lambda no ambiente `GridWorld4x3`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Grid 4x3"
      ],
      "metadata": {
        "id": "M-qQL1MWzlpa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "import numpy as np\n",
        "from typing import Optional,Iterable,Tuple\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "class GridWorld4x3(gym.Env):\n",
        "    metadata = {\"render_modes\": [\"ansi\"]}\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        reward_step: float = -0.04,\n",
        "        slip: float = 0.2,\n",
        "        max_steps: int = 1000,\n",
        "        seed: Optional[int] = None,\n",
        "        render_mode: Optional[str] = None,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.ncols = 4\n",
        "        self.nrows = 3\n",
        "        self.observation_space = spaces.Discrete(self.ncols * self.nrows)\n",
        "        self.action_space = spaces.Discrete(4)  # 0=up, 1=right, 2=down, 3=left\n",
        "\n",
        "        self.reward_step = reward_step\n",
        "        self.slip = slip\n",
        "        self.max_steps = max_steps\n",
        "        self.render_mode = render_mode\n",
        "\n",
        "        self.start_pos = (0, 0)\n",
        "        self.goal_pos = (3, 2)  # state 11\n",
        "        self.pit_pos = (3, 1)   # state 7\n",
        "        self.wall_pos = (1, 1)  # state 5 (inacessível)\n",
        "\n",
        "        self._rng = np.random.default_rng(seed)\n",
        "        self.steps = 0\n",
        "        self.agent_pos = self.start_pos\n",
        "\n",
        "        # Movimentos: up, right, down, left\n",
        "        self.moves = [(0, 1), (1, 0), (0, -1), (-1, 0)]\n",
        "\n",
        "    # ---------- conversão estado/posição ----------\n",
        "    def pos_to_state(self, pos):\n",
        "        x, y = pos\n",
        "        return y * self.ncols + x\n",
        "\n",
        "    def state_to_pos(self, s):\n",
        "        return (s % self.ncols, s // self.ncols)\n",
        "\n",
        "    # ---------- helpers internos ----------\n",
        "    def _move(self, pos, action):\n",
        "        dx, dy = self.moves[action]\n",
        "        x, y = pos\n",
        "        new_pos = (x + dx, y + dy)\n",
        "        # checa limites e parede\n",
        "        if not (0 <= new_pos[0] < self.ncols and 0 <= new_pos[1] < self.nrows):\n",
        "            return pos\n",
        "        if new_pos == self.wall_pos:\n",
        "            return pos\n",
        "        return new_pos\n",
        "\n",
        "    def _reward_and_done(self, pos):\n",
        "        if pos == self.goal_pos:\n",
        "            return 1.0, True\n",
        "        elif pos == self.pit_pos:\n",
        "            return -1.0, True\n",
        "        return self.reward_step, False\n",
        "\n",
        "    # ---------- API Gym ----------\n",
        "    def reset(self, *, seed: Optional[int] = None, options: Optional[dict] = None):\n",
        "        super().reset(seed=seed)\n",
        "        self.agent_pos = self.start_pos\n",
        "        self.steps = 0\n",
        "        return self.pos_to_state(self.agent_pos), {}\n",
        "\n",
        "    def step(self, action):\n",
        "        self.steps += 1\n",
        "\n",
        "        # sorteia se escorrega\n",
        "        if self._rng.random() < self.slip:\n",
        "            if action in [0, 2]:  # up/down → troca por left/right\n",
        "                action = self._rng.choice([1, 3])\n",
        "            else:  # left/right → troca por up/down\n",
        "                action = self._rng.choice([0, 2])\n",
        "\n",
        "        self.agent_pos = self._move(self.agent_pos, action)\n",
        "        reward, terminated = self._reward_and_done(self.agent_pos)\n",
        "        truncated = self.steps >= self.max_steps\n",
        "\n",
        "        return self.pos_to_state(self.agent_pos), reward, terminated, truncated, {}\n",
        "\n",
        "    # ----------------------------\n",
        "    # Rendering\n",
        "    # ----------------------------\n",
        "    def render(self, mode=\"ansi\"):\n",
        "        if mode == \"ansi\":\n",
        "            return self._render_ansi()\n",
        "        else:\n",
        "            raise NotImplementedError\n",
        "\n",
        "    def _render_ansi(self):\n",
        "        out = \"\"\n",
        "        for y in reversed(range(self.nrows)):\n",
        "            out += \"+----\" * self.ncols + \"+\\n\"\n",
        "            for x in range(self.ncols):\n",
        "                pos = (x, y)\n",
        "                s = self.pos_to_state(pos)\n",
        "                cell = f\"{s:2d} \"\n",
        "                if pos == self.wall_pos:\n",
        "                    cell = \" ## \"\n",
        "                elif pos == self.goal_pos:\n",
        "                    cell = f\"{s:2d}G\"\n",
        "                elif pos == self.pit_pos:\n",
        "                    cell = f\"{s:2d}P\"\n",
        "                elif pos == self.start_pos:\n",
        "                    cell = f\"{s:2d}S\"\n",
        "                if self.agent_pos == self.state_to_pos(s):\n",
        "                    cell = f\"[{cell.strip()}]\"\n",
        "                out += f\"|{cell:4}\"\n",
        "            out += \"|\\n\"\n",
        "        out += \"+----\" * self.ncols + \"+\\n\"\n",
        "        return out\n",
        "\n"
      ],
      "metadata": {
        "id": "evNquQ94zjgh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Código dos agentes"
      ],
      "metadata": {
        "id": "iaIkDdHdxYv8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TDAgent"
      ],
      "metadata": {
        "id": "eOTXAQWqxWRd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from abc import ABC,abstractmethod\n",
        "\n",
        "class TDAgent(ABC):\n",
        "    def __init__(self, env: gym.Env, alpha: float = 0.1, gamma: float = 0.99, epsilon: float = 0.1):\n",
        "        \"\"\"\n",
        "        Construtor do agente TD.\n",
        "\n",
        "        Args:\n",
        "            env: ambiente Gymnasium (ex: gridworld 4x3).\n",
        "            alpha: taxa de aprendizado.\n",
        "            gamma: fator de desconto.\n",
        "            epsilon: taxa de exploração (para política epsilon-greedy).\n",
        "        \"\"\"\n",
        "        self.env = env\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "        obs_space_size = env.observation_space.n\n",
        "        act_space_size = env.action_space.n\n",
        "        self.q_values = np.zeros((obs_space_size, act_space_size))\n",
        "\n",
        "    def Q(self, state, action) -> float:\n",
        "      \"\"\"Retorna Q(s,a).\"\"\"\n",
        "      return self.q_values[state, action]\n",
        "\n",
        "    def V(self, state) -> float:\n",
        "      \"\"\"Retorna V(s) = max_a Q(s,a).\"\"\"\n",
        "      return np.max(self.q_values[state, :])\n",
        "\n",
        "    def greedy_action(self, state) -> int:\n",
        "      \"\"\"Retorna a ação gulosa (argmax_a Q(s,a)).\"\"\"\n",
        "      return np.argmax(self.q_values[state, :])\n",
        "\n",
        "    def act(self, state) -> int:\n",
        "      \"\"\"Retorna ação epsilon-greedy.\"\"\"\n",
        "      if np.random.rand() < self.epsilon:\n",
        "          return self.env.action_space.sample()\n",
        "      else:\n",
        "          return self.greedy_action(state)\n",
        "\n",
        "    @abstractmethod\n",
        "    def train(self, steps: int):\n",
        "      \"\"\"\n",
        "      Executa o treinamento por um número de passos.\n",
        "\n",
        "      Args:\n",
        "          steps: número de passos de treino.\n",
        "      \"\"\"\n",
        "      pass\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gIfKwXNTtxFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sarsa"
      ],
      "metadata": {
        "id": "L6uKxkhuxTq8"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ea1b20c"
      },
      "source": [
        "class SarsaAgent(TDAgent):\n",
        "    def updateQ(self, s, a, r, s_next, a_next, done: bool):\n",
        "        \"\"\"Atualiza Q(s,a) segundo a regra do SARSA.\"\"\"\n",
        "        q_next = self.Q(s_next, a_next) if not done else 0\n",
        "        self.q_values[s, a] += self.alpha * (r + self.gamma * q_next - self.Q(s, a))\n",
        "\n",
        "    def train(self, steps: int):\n",
        "        state, _ = self.env.reset()\n",
        "        action = self.act(state)\n",
        "        for step in range(steps):\n",
        "            new_state, reward, terminated, truncated, _ = self.env.step(action)\n",
        "            new_action = self.act(new_state)\n",
        "            done = terminated or truncated\n",
        "            self.updateQ(state, action, reward, new_state, new_action, done)\n",
        "            state = new_state\n",
        "            action = new_action\n",
        "            if done:\n",
        "                state, _ = self.env.reset()\n",
        "                action = self.act(state)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SarsaLambda"
      ],
      "metadata": {
        "id": "MqcU27ChxQvB"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c75f1d4a"
      },
      "source": [
        "class SarsaLambdaAgent(SarsaAgent):\n",
        "    def __init__(self, env: gym.Env, alpha: float = 0.1, gamma: float = 0.99, epsilon: float = 0.1, lambda_: float = 0.9):\n",
        "        \"\"\"\n",
        "        Construtor do agente SARSA(lambda).\n",
        "\n",
        "        Args:\n",
        "            env: ambiente Gymnasium (ex: gridworld 4x3).\n",
        "            alpha: taxa de aprendizado.\n",
        "            gamma: fator de desconto.\n",
        "            epsilon: taxa de exploração (para política epsilon-greedy).\n",
        "            lambda_: fator de decaimento para as trilhas de elegibilidade.\n",
        "        \"\"\"\n",
        "        super().__init__(env, alpha, gamma, epsilon)\n",
        "        self.lambda_ = lambda_\n",
        "        # nao esqueca de atualizar os tracos de elegibilidade\n",
        "        self.e = np.zeros((self.env.observation_space.n, self.env.action_space.n))\n",
        "\n",
        "    def updateQ(self, s, a, r, s_next, a_next, done: bool):\n",
        "        \"\"\"Atualiza Q(s,a) segundo a regra do SARSA.\"\"\"\n",
        "        q_next = self.Q(s_next, a_next) if not done else 0\n",
        "        delta = r + self.gamma * q_next - self.Q(s, a)\n",
        "        self.e[s, a] = 1\n",
        "        for s in range(self.env.observation_space.n):\n",
        "            for a in range(self.env.action_space.n):\n",
        "                self.q_values[s, a] += self.alpha * r * self.e[s, a]\n",
        "                self.e[s,a] *= self.gamma * self.lambda_\n",
        "\n",
        "    def train(self, steps: int):\n",
        "        total_rewards = 0\n",
        "        state, _ = self.env.reset()\n",
        "        action = self.act(state)\n",
        "        for step in range(steps):\n",
        "            new_state, reward, terminated, truncated, _ = self.env.step(action)\n",
        "            done = terminated or truncated\n",
        "            total_rewards += reward\n",
        "            new_action = self.act(new_state)\n",
        "            self.updateQ(state, action, reward, new_state, new_action, done)\n",
        "            state = new_state\n",
        "            action = new_action\n",
        "            if done:\n",
        "                state, _ = self.env.reset()\n",
        "                action = self.act(state)\n",
        "                self.e = np.zeros((self.env.observation_space.n, self.env.action_space.n))\n",
        "        return total_rewards\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizador do agente"
      ],
      "metadata": {
        "id": "jA8u4Iesw9Ru"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Para o Grid 4x3"
      ],
      "metadata": {
        "id": "Wzw5lnXmzxrD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Grid4x3AgentVisualizer:\n",
        "    def __init__(self, agent, env):\n",
        "        \"\"\"\n",
        "        agent: ValueIterationAgent-like (tem V(s), Q(s,a) e greedy_action(s))\n",
        "        env: GridWorld4x3-like (tem nrows, ncols, pos_to_state, state_to_pos, is_terminal, get_states, start_pos, goal_pos, pit_pos, wall_pos)\n",
        "        \"\"\"\n",
        "        self.agent = agent\n",
        "        self.env = env\n",
        "        self.action_to_str = {0: \"↑\", 1: \"→\", 2: \"↓\", 3: \"←\"}\n",
        "\n",
        "        # Precompute special states\n",
        "        self.wall_s = self.env.pos_to_state(self.env.wall_pos)\n",
        "        self.start_s = self.env.pos_to_state(self.env.start_pos)\n",
        "        self.goal_s = self.env.pos_to_state(self.env.goal_pos)\n",
        "        self.pit_s = self.env.pos_to_state(self.env.pit_pos)\n",
        "\n",
        "    # -----------------------\n",
        "    # Política (setas)\n",
        "    # -----------------------\n",
        "    def print_policy(self):\n",
        "        rows, cols = self.env.nrows, self.env.ncols\n",
        "        horiz = \"+\" + \"+\".join([\"------\"] * cols) + \"+\"\n",
        "\n",
        "        for y in reversed(range(rows)):\n",
        "            print(horiz)\n",
        "            cells = []\n",
        "            for x in range(cols):\n",
        "                s = self.env.pos_to_state((x, y))\n",
        "                if s == self.wall_s:\n",
        "                    content = \"##\"\n",
        "                elif s == self.goal_s:\n",
        "                    content = \" G \"\n",
        "                elif s == self.pit_s:\n",
        "                    content = \" P \"\n",
        "                else:\n",
        "                    a = self.agent.greedy_action(s)\n",
        "                    arrow = self.action_to_str.get(a, \"?\")\n",
        "                    if s == self.start_s:\n",
        "                        content = f\"S{arrow}\"\n",
        "                    else:\n",
        "                        content = arrow\n",
        "                cells.append(f\"{content:^6}\")\n",
        "            print(\"|\" + \"|\".join(cells) + \"|\")\n",
        "        print(horiz)\n",
        "\n",
        "    # -----------------------\n",
        "    # Valores V(s)\n",
        "    # -----------------------\n",
        "    def print_values(self):\n",
        "        rows, cols = self.env.nrows, self.env.ncols\n",
        "        horiz = \"+\" + \"+\".join([\"--------\"] * cols) + \"+\"\n",
        "\n",
        "        for y in reversed(range(rows)):\n",
        "            print(horiz)\n",
        "            cells = []\n",
        "            for x in range(cols):\n",
        "                s = self.env.pos_to_state((x, y))\n",
        "                if s == self.wall_s:\n",
        "                    content = \"####\"\n",
        "                else:\n",
        "                    v = self.agent.V(s)\n",
        "                    if s == self.goal_s:\n",
        "                        content = f\"G({v:.2f})\"\n",
        "                    elif s == self.pit_s:\n",
        "                        content = f\"P({v:.2f})\"\n",
        "                    else:\n",
        "                        content = f\"{v:6.2f}\"\n",
        "                cells.append(f\"{content:^8}\")\n",
        "            print(\"|\" + \"|\".join(cells) + \"|\")\n",
        "        print(horiz)\n",
        "\n",
        "    # -----------------------\n",
        "    # Q-values\n",
        "    # -----------------------\n",
        "    def print_qvalues(self):\n",
        "        rows, cols = self.env.nrows, self.env.ncols\n",
        "        horiz = \"+\" + \"+\".join([\"---------------\"] * cols) + \"+\"\n",
        "\n",
        "        for y in reversed(range(rows)):\n",
        "            print(horiz)\n",
        "            # três linhas por célula\n",
        "            line1, line2, line3 = [], [], []\n",
        "            for x in range(cols):\n",
        "                s = self.env.pos_to_state((x, y))\n",
        "                if s == self.wall_s:\n",
        "                    c1 = \"###############\"\n",
        "                    c2 = \"###############\"\n",
        "                    c3 = \"###############\"\n",
        "                else:\n",
        "                    qvals = [self.agent.Q(s, a) for a in range(4)]\n",
        "                    best = int(np.argmax(qvals))\n",
        "                    up = f\"↑:{qvals[0]:.2f}\"\n",
        "                    left = f\"←:{qvals[3]:.2f}\"\n",
        "                    right = f\"→:{qvals[1]:.2f}\"\n",
        "                    down = f\"↓:{qvals[2]:.2f}\"\n",
        "                    c1 = f\"{up:^15}\"\n",
        "                    c2 = f\"{left:<7}{right:>8}\"\n",
        "                    c3 = f\"{down:^15}\"\n",
        "                line1.append(c1)\n",
        "                line2.append(c2)\n",
        "                line3.append(c3)\n",
        "\n",
        "            # agora cada linha recebe delimitadores\n",
        "            print(\"|\" + \"|\".join(line1) + \"|\")\n",
        "            print(\"|\" + \"|\".join(line2) + \"|\")\n",
        "            print(\"|\" + \"|\".join(line3) + \"|\")\n",
        "        print(horiz)\n"
      ],
      "metadata": {
        "id": "mbJsXXokz0EW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Executando os agentes\n",
        "\n"
      ],
      "metadata": {
        "id": "eJEyZhiWxM4t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Teste 1: episódios simples\n",
        "\n",
        "Resultado esperado após acima, acima, dir, dir, dir (vitória):\n",
        "\n",
        "```\n",
        "Sarsa Agent Q-values after actions  [0, 0, 1, 1, 1]\n",
        "+---------------+---------------+---------------+---------------+\n",
        "|    ↑:0.00     |    ↑:0.00     |    ↑:0.00     |    ↑:0.00     |\n",
        "|←:0.00   →:0.00|←:0.00   →:0.00|←:0.00   →:0.50|←:0.00   →:0.00|\n",
        "|    ↓:0.00     |    ↓:0.00     |    ↓:0.00     |    ↓:0.00     |\n",
        "+---------------+---------------+---------------+---------------+\n",
        "|    ↑:0.00     |###############|    ↑:0.00     |    ↑:0.00     |\n",
        "|←:0.00   →:0.00|###############|←:0.00   →:0.00|←:0.00   →:0.00|\n",
        "|    ↓:0.00     |###############|    ↓:0.00     |    ↓:0.00     |\n",
        "+---------------+---------------+---------------+---------------+\n",
        "|    ↑:0.00     |    ↑:0.00     |    ↑:0.00     |    ↑:0.00     |\n",
        "|←:0.00   →:0.00|←:0.00   →:0.00|←:0.00   →:0.00|←:0.00   →:0.00|\n",
        "|    ↓:0.00     |    ↓:0.00     |    ↓:0.00     |    ↓:0.00     |\n",
        "+---------------+---------------+---------------+---------------+\n",
        "\n",
        "SarsaLambda Agent Q-Values actions:  [0, 0, 1, 1, 1]\n",
        "+---------------+---------------+---------------+---------------+\n",
        "|    ↑:0.00     |    ↑:0.00     |    ↑:0.00     |    ↑:0.00     |\n",
        "|←:0.00   →:0.33|←:0.00   →:0.41|←:0.00   →:0.50|←:0.00   →:0.00|\n",
        "|    ↓:0.00     |    ↓:0.00     |    ↓:0.00     |    ↓:0.00     |\n",
        "+---------------+---------------+---------------+---------------+\n",
        "|    ↑:0.27     |###############|    ↑:0.00     |    ↑:0.00     |\n",
        "|←:0.00   →:0.00|###############|←:0.00   →:0.00|←:0.00   →:0.00|\n",
        "|    ↓:0.00     |###############|    ↓:0.00     |    ↓:0.00     |\n",
        "+---------------+---------------+---------------+---------------+\n",
        "|    ↑:0.22     |    ↑:0.00     |    ↑:0.00     |    ↑:0.00     |\n",
        "|←:0.00   →:0.00|←:0.00   →:0.00|←:0.00   →:0.00|←:0.00   →:0.00|\n",
        "|    ↓:0.00     |    ↓:0.00     |    ↓:0.00     |    ↓:0.00     |\n",
        "+---------------+---------------+---------------+---------------+\n",
        "```"
      ],
      "metadata": {
        "id": "VsKn3gJOQFhy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "simple_episode_win = [0, 0, 1, 1, 1] #up, up, right, right, right\n",
        "\n",
        "env1 = GridWorld4x3(slip=0, reward_step=0)\n",
        "env2 = GridWorld4x3(slip=0, reward_step=0)\n",
        "\n",
        "sarsa_agent = SarsaAgent(env1, alpha=0.5, gamma=0.9, epsilon=0.1)\n",
        "esarsa_agent = SarsaLambdaAgent(env2, alpha=0.5, gamma=0.9, epsilon=0.1, lambda_=0.9)\n",
        "\n",
        "state1, _ = env1.reset()\n",
        "state2, _ = env2.reset()\n",
        "\n",
        "#run both agents\n",
        "for i, action in enumerate(simple_episode_win):\n",
        "    next_state, reward, terminated, truncated, _ = env1.step(action)\n",
        "    done1 = terminated or truncated\n",
        "\n",
        "    next_state2, reward2, terminated2, truncated2, _ = env2.step(action)\n",
        "    done2 = terminated2 or truncated2\n",
        "\n",
        "    if not (done1):\n",
        "      next_action = simple_episode_win[i+1]\n",
        "      next_action2 = simple_episode_win[i+1]\n",
        "    else:\n",
        "      next_action = None\n",
        "      next_action2 = None\n",
        "\n",
        "    sarsa_agent.updateQ(state1, action, reward, next_state, next_action, done1)\n",
        "    esarsa_agent.updateQ(state2, action, reward2, next_state2, next_action2, done2)\n",
        "\n",
        "    state1 = next_state\n",
        "    state2 = next_state2\n",
        "\n",
        "\n",
        "# Visualize what each agent learned after 1 episode\n",
        "print(\"\\nSarsa Agent Q-values after actions \", simple_episode_win)\n",
        "grid_visualizer_sarsa = Grid4x3AgentVisualizer(sarsa_agent, env1)\n",
        "grid_visualizer_sarsa.print_qvalues()\n",
        "\n",
        "print(\"\\nSarsaLambda Agent Q-Values actions: \", simple_episode_win)\n",
        "grid_visualizer_sarsa_lambda = Grid4x3AgentVisualizer(esarsa_agent, env2)\n",
        "grid_visualizer_sarsa_lambda.print_qvalues()\n"
      ],
      "metadata": {
        "id": "PfhBqa6mNOOb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b240ede3-3cb2-4745-806f-7d81b8d61edd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sarsa Agent Q-values after actions  [0, 0, 1, 1, 1]\n",
            "+---------------+---------------+---------------+---------------+\n",
            "|    ↑:0.00     |    ↑:0.00     |    ↑:0.00     |    ↑:0.00     |\n",
            "|←:0.00   →:0.00|←:0.00   →:0.00|←:0.00   →:0.50|←:0.00   →:0.00|\n",
            "|    ↓:0.00     |    ↓:0.00     |    ↓:0.00     |    ↓:0.00     |\n",
            "+---------------+---------------+---------------+---------------+\n",
            "|    ↑:0.00     |###############|    ↑:0.00     |    ↑:0.00     |\n",
            "|←:0.00   →:0.00|###############|←:0.00   →:0.00|←:0.00   →:0.00|\n",
            "|    ↓:0.00     |###############|    ↓:0.00     |    ↓:0.00     |\n",
            "+---------------+---------------+---------------+---------------+\n",
            "|    ↑:0.00     |    ↑:0.00     |    ↑:0.00     |    ↑:0.00     |\n",
            "|←:0.00   →:0.00|←:0.00   →:0.00|←:0.00   →:0.00|←:0.00   →:0.00|\n",
            "|    ↓:0.00     |    ↓:0.00     |    ↓:0.00     |    ↓:0.00     |\n",
            "+---------------+---------------+---------------+---------------+\n",
            "\n",
            "SarsaLambda Agent Q-Values actions:  [0, 0, 1, 1, 1]\n",
            "+---------------+---------------+---------------+---------------+\n",
            "|    ↑:0.00     |    ↑:0.00     |    ↑:0.00     |    ↑:0.00     |\n",
            "|←:0.00   →:0.33|←:0.00   →:0.41|←:0.00   →:0.50|←:0.00   →:0.00|\n",
            "|    ↓:0.00     |    ↓:0.00     |    ↓:0.00     |    ↓:0.00     |\n",
            "+---------------+---------------+---------------+---------------+\n",
            "|    ↑:0.27     |###############|    ↑:0.00     |    ↑:0.00     |\n",
            "|←:0.00   →:0.00|###############|←:0.00   →:0.00|←:0.00   →:0.00|\n",
            "|    ↓:0.00     |###############|    ↓:0.00     |    ↓:0.00     |\n",
            "+---------------+---------------+---------------+---------------+\n",
            "|    ↑:0.22     |    ↑:0.00     |    ↑:0.00     |    ↑:0.00     |\n",
            "|←:0.00   →:0.00|←:0.00   →:0.00|←:0.00   →:0.00|←:0.00   →:0.00|\n",
            "|    ↓:0.00     |    ↓:0.00     |    ↓:0.00     |    ↓:0.00     |\n",
            "+---------------+---------------+---------------+---------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Após mais um episódio\n",
        "\n",
        "Executar esta celula após a anterior, pois a ideia é ver o conhecimento acumulado do agente após dois episódios.\n",
        "\n",
        "Se rodar essa célula 2x seguidas, vc não obterá os resultados esperados.\n",
        "\n",
        "Resultado esperado após dir, dir, dir, acima (derrota):\n",
        "```\n",
        "Sarsa Agent Q-values after actions  [1, 1, 1, 0]\n",
        "+---------------+---------------+---------------+---------------+\n",
        "|    ↑:0.00     |    ↑:0.00     |    ↑:0.00     |    ↑:0.00     |\n",
        "|←:0.00   →:0.00|←:0.00   →:0.00|←:0.00   →:0.50|←:0.00   →:0.00|\n",
        "|    ↓:0.00     |    ↓:0.00     |    ↓:0.00     |    ↓:0.00     |\n",
        "+---------------+---------------+---------------+---------------+\n",
        "|    ↑:0.00     |###############|    ↑:0.00     |    ↑:0.00     |\n",
        "|←:0.00   →:0.00|###############|←:0.00   →:0.00|←:0.00   →:0.00|\n",
        "|    ↓:0.00     |###############|    ↓:0.00     |    ↓:0.00     |\n",
        "+---------------+---------------+---------------+---------------+\n",
        "|    ↑:0.00     |    ↑:0.00     |    ↑:0.00     |    ↑:-0.50    |\n",
        "|←:0.00   →:0.00|←:0.00   →:0.00|←:0.00   →:0.00|←:0.00   →:0.00|\n",
        "|    ↓:0.00     |    ↓:0.00     |    ↓:0.00     |    ↓:0.00     |\n",
        "+---------------+---------------+---------------+---------------+\n",
        "\n",
        "SarsaLambda Agent Q-Values actions:  [1, 1, 1, 0]\n",
        "+---------------+---------------+---------------+---------------+\n",
        "|    ↑:0.00     |    ↑:0.00     |    ↑:0.00     |    ↑:0.00     |\n",
        "|←:0.00   →:0.33|←:0.00   →:0.41|←:0.00   →:0.50|←:0.00   →:0.00|\n",
        "|    ↓:0.00     |    ↓:0.00     |    ↓:0.00     |    ↓:0.00     |\n",
        "+---------------+---------------+---------------+---------------+\n",
        "|    ↑:0.27     |###############|    ↑:0.00     |    ↑:0.00     |\n",
        "|←:0.00   →:0.00|###############|←:0.00   →:0.00|←:0.00   →:0.00|\n",
        "|    ↓:0.00     |###############|    ↓:0.00     |    ↓:0.00     |\n",
        "+---------------+---------------+---------------+---------------+\n",
        "|    ↑:0.22     |    ↑:0.00     |    ↑:-0.22    |    ↑:-0.50    |\n",
        "|←:0.00  →:-0.27|←:0.00  →:-0.33|←:0.00  →:-0.41|←:0.00   →:0.00|\n",
        "|    ↓:0.00     |    ↓:0.00     |    ↓:0.00     |    ↓:0.00     |\n",
        "+---------------+---------------+---------------+---------------+\n",
        "```"
      ],
      "metadata": {
        "id": "n0CF_q1ARBRn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "simple_episode_loss = [1, 1, 1, 0] #right, right, right up (defeat)\n",
        "\n",
        "# executar esta celula após a anterior; se rodar essa 2x seguidas, vc não obterá os resultados esperados\n",
        "state1, _ = env1.reset()\n",
        "state2, _ = env2.reset()\n",
        "\n",
        "#run both agents\n",
        "for i, action in enumerate(simple_episode_loss):\n",
        "    next_state, reward, terminated, truncated, _ = env1.step(action)\n",
        "    done1 = terminated or truncated\n",
        "\n",
        "    next_state2, reward2, terminated2, truncated2, _ = env2.step(action)\n",
        "    done2 = terminated2 or truncated2\n",
        "\n",
        "    if not (done1):\n",
        "      next_action = simple_episode_loss[i+1]\n",
        "      next_action2 = simple_episode_loss[i+1]\n",
        "    else:\n",
        "      next_action = None\n",
        "      next_action2 = None\n",
        "\n",
        "    sarsa_agent.updateQ(state1, action, reward, next_state, next_action, done1)\n",
        "    esarsa_agent.updateQ(state2, action, reward2, next_state2, next_action2, done2)\n",
        "\n",
        "    state1 = next_state\n",
        "    state2 = next_state2\n",
        "\n",
        "\n",
        "# Visualize what each agent learned after 1 episode\n",
        "print(\"\\nSarsa Agent Q-values after actions \", simple_episode_loss)\n",
        "grid_visualizer_sarsa = Grid4x3AgentVisualizer(sarsa_agent, env1)\n",
        "grid_visualizer_sarsa.print_qvalues()\n",
        "\n",
        "print(\"\\nSarsaLambda Agent Q-Values actions: \", simple_episode_loss)\n",
        "grid_visualizer_sarsa_lambda = Grid4x3AgentVisualizer(esarsa_agent, env2)\n",
        "grid_visualizer_sarsa_lambda.print_qvalues()\n"
      ],
      "metadata": {
        "id": "uMKQR2DAQCEo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d5d794f-7525-43fc-c4cc-7f07609aaa7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sarsa Agent Q-values after actions  [1, 1, 1, 0]\n",
            "+---------------+---------------+---------------+---------------+\n",
            "|    ↑:0.00     |    ↑:0.00     |    ↑:0.00     |    ↑:0.00     |\n",
            "|←:0.00   →:0.00|←:0.00   →:0.00|←:0.00   →:0.50|←:0.00   →:0.00|\n",
            "|    ↓:0.00     |    ↓:0.00     |    ↓:0.00     |    ↓:0.00     |\n",
            "+---------------+---------------+---------------+---------------+\n",
            "|    ↑:0.00     |###############|    ↑:0.00     |    ↑:0.00     |\n",
            "|←:0.00   →:0.00|###############|←:0.00   →:0.00|←:0.00   →:0.00|\n",
            "|    ↓:0.00     |###############|    ↓:0.00     |    ↓:0.00     |\n",
            "+---------------+---------------+---------------+---------------+\n",
            "|    ↑:0.00     |    ↑:0.00     |    ↑:0.00     |    ↑:-0.50    |\n",
            "|←:0.00   →:0.00|←:0.00   →:0.00|←:0.00   →:0.00|←:0.00   →:0.00|\n",
            "|    ↓:0.00     |    ↓:0.00     |    ↓:0.00     |    ↓:0.00     |\n",
            "+---------------+---------------+---------------+---------------+\n",
            "\n",
            "SarsaLambda Agent Q-Values actions:  [1, 1, 1, 0]\n",
            "+---------------+---------------+---------------+---------------+\n",
            "|    ↑:0.00     |    ↑:0.00     |    ↑:0.00     |    ↑:0.00     |\n",
            "|←:0.00   →:0.19|←:0.00   →:0.23|←:0.00   →:0.28|←:0.00   →:0.00|\n",
            "|    ↓:0.00     |    ↓:0.00     |    ↓:0.00     |    ↓:0.00     |\n",
            "+---------------+---------------+---------------+---------------+\n",
            "|    ↑:0.15     |###############|    ↑:0.00     |    ↑:0.00     |\n",
            "|←:0.00   →:0.00|###############|←:0.00   →:0.00|←:0.00   →:0.00|\n",
            "|    ↓:0.00     |###############|    ↓:0.00     |    ↓:0.00     |\n",
            "+---------------+---------------+---------------+---------------+\n",
            "|    ↑:0.12     |    ↑:0.00     |    ↑:0.00     |    ↑:-0.50    |\n",
            "|←:0.00  →:-0.27|←:0.00  →:-0.33|←:0.00  →:-0.41|←:0.00   →:0.00|\n",
            "|    ↓:0.00     |    ↓:0.00     |    ↓:0.00     |    ↓:0.00     |\n",
            "+---------------+---------------+---------------+---------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Treine seu agente no Grid 4x3\n",
        "\n",
        "O grid terá os parâmetros: slip=0, reward_step=-0.1. Os agentes terão: alpha = 0.5, gamma = 0.9, epsilon = 0.1\n",
        "\n",
        "Treine os agentes por 100 passos.\n",
        "\n",
        "Analise as a políticas resultantes e os valores aprendidos para as seguintes lambdas: 0.1, 0.3, 0.5, 0.7, 0.9.\n",
        "\n",
        "Execute 1000 repetições de cada experimento e gere um gráfico de barras com a recompensa média obtida para cada lambda (adapte sua função de treino pra retornar a recompensa acumulada pelo agente).\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "JS8EjW9t17Hn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "# =======================\n",
        "# Execução do SarsaLambda Agent no Grid 4x3\n",
        "# =======================\n",
        "NUM_AGENTS = 5\n",
        "LAMBDAS = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
        "NUM_STEPS = 100\n",
        "NUM_REPETITIONS = 1000\n",
        "\n",
        "env_grid = GridWorld4x3(slip=0.0, reward_step=-0.1)\n",
        "agents = [SarsaLambdaAgent(env_grid, alpha=0.5, gamma=0.9, epsilon=0.1, lambda_=LAMBDAS[i]) for i in range(NUM_AGENTS)]\n",
        "agent_means = np.zeros(NUM_AGENTS)\n",
        "\n",
        "for _ in tqdm(range(NUM_REPETITIONS)):\n",
        "    for i, agent in enumerate(agents):\n",
        "        agent_means[i] += agent.train(steps=NUM_STEPS)\n",
        "\n",
        "agent_means /= NUM_REPETITIONS\n",
        "\n",
        "plt.bar([str(l) for l in LAMBDAS], agent_means)\n",
        "plt.title('Mean Reward X Agent Lambda')\n",
        "plt.xlabel('Agent Lambda')\n",
        "plt.ylabel('Mean Reward Received')\n",
        "plt.show()\n",
        "\n",
        "for i, agent in enumerate(agents):\n",
        "    print(f\"\\n=== Política Aprendida (Lambda {LAMBDAS[i]}) ===\")\n",
        "    Grid4x3AgentVisualizer(agent, env_grid).print_policy()"
      ],
      "metadata": {
        "id": "bCgKJuLcwACM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2ac08cd1-02b7-4c9c-8536-4bb8faae6eaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:35<00:00, 28.15it/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Política Aprendida (Lambda 0.1) ===\n",
            "+------+------+------+------+\n",
            "|  ←   |  →   |  →   |  G   |\n",
            "+------+------+------+------+\n",
            "|  ↑   |  ##  |  ↑   |  P   |\n",
            "+------+------+------+------+\n",
            "|  S→  |  ↓   |  ↓   |  ↓   |\n",
            "+------+------+------+------+\n",
            "\n",
            "=== Política Aprendida (Lambda 0.3) ===\n",
            "+------+------+------+------+\n",
            "|  ↓   |  →   |  →   |  G   |\n",
            "+------+------+------+------+\n",
            "|  ↓   |  ##  |  ↑   |  P   |\n",
            "+------+------+------+------+\n",
            "|  S←  |  →   |  ←   |  ↓   |\n",
            "+------+------+------+------+\n",
            "\n",
            "=== Política Aprendida (Lambda 0.5) ===\n",
            "+------+------+------+------+\n",
            "|  →   |  →   |  →   |  G   |\n",
            "+------+------+------+------+\n",
            "|  ↑   |  ##  |  ↑   |  P   |\n",
            "+------+------+------+------+\n",
            "|  S←  |  ←   |  ↑   |  ↓   |\n",
            "+------+------+------+------+\n",
            "\n",
            "=== Política Aprendida (Lambda 0.7) ===\n",
            "+------+------+------+------+\n",
            "|  →   |  →   |  →   |  G   |\n",
            "+------+------+------+------+\n",
            "|  ↑   |  ##  |  ↑   |  P   |\n",
            "+------+------+------+------+\n",
            "|  S→  |  →   |  ↑   |  ←   |\n",
            "+------+------+------+------+\n",
            "\n",
            "=== Política Aprendida (Lambda 0.9) ===\n",
            "+------+------+------+------+\n",
            "|  →   |  →   |  →   |  G   |\n",
            "+------+------+------+------+\n",
            "|  ↑   |  ##  |  ↑   |  P   |\n",
            "+------+------+------+------+\n",
            "|  S→  |  →   |  ↑   |  ←   |\n",
            "+------+------+------+------+\n"
          ]
        }
      ]
    }
  ]
}